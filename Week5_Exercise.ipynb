{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6cd4e5",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from util_func import *\n",
    "import scipy\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#modify transformation matrix\n",
    "img = cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "yc, xc = h //2, w //2\n",
    "angle = 45 \n",
    "\n",
    "#get transformaton matrix\n",
    "M = cv.getRotationMatrix2D((xc, yc), angle, 1)\n",
    "\n",
    "#M = |cos(theta) -sin(theta) tx|\n",
    "#    |sin(theta) cos(theta)  ty|\n",
    "cosine = abs(M[0, 0])\n",
    "sine = abs(M[0, 1])\n",
    "\n",
    "#x' = ax + by [a=>scalling component in x-direction | b=> rotation comp in x-direction]\n",
    "#y' = cx + dy \n",
    "new_w = int((h * sine) + (w * cosine)) # h*sine => anount of distance extends vertically | w*cosine => horizontally | sum to get total width\n",
    "new_h = int((h * cosine) + (w * sine)) # h*cosine => vertical | w*sine => horizontal\n",
    "\n",
    "M[0, 2] += (new_w / 2) - xc #move img back to center\n",
    "M[1, 2] += (new_h / 2) - yc\n",
    "\n",
    "dst = cv.warpAffine(img, M, (new_w, new_h))\n",
    "\n",
    "show_img(\"rotation\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339357ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "img = cv.imread(\"images/lena.jfif\")\n",
    "rotated_image = imutils.rotate_bound(img, angle=45)\n",
    "show_img(\"rotation\", rotated_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c92b1",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334c64db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bee_img = cv.imread(\"images/native-bee.png\")\n",
    "flower_img = cv.imread(\"images/flower.jfif\")\n",
    "\n",
    "# Define the position to place the flower in the bee image\n",
    "x_pos = 5 \n",
    "y_pos = 5  \n",
    "\n",
    "flower_height, flower_width = flower_img.shape[:2]\n",
    "\n",
    "# Convert flower image to grayscale\n",
    "gray_flower = cv.cvtColor(flower_img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the grayscale flower image to create a mask\n",
    "mask = cv.threshold(gray_flower, 70, 255, cv.THRESH_BINARY)[1]\n",
    "\n",
    "# Invert the mask to keep only non-black pixels\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    "\n",
    "# Extract the region of interest (ROI) from the bee image\n",
    "roi = bee_img[y_pos:y_pos + flower_height, x_pos:x_pos + flower_width]\n",
    "\n",
    "# Use the mask to keep only the flower pixels and blend it with the ROI\n",
    "roi_result = cv.bitwise_and(roi, roi, mask=mask_inv)\n",
    "flower_result = cv.bitwise_and(flower_img, flower_img, mask=mask)\n",
    "result = cv.add(roi_result, flower_result)\n",
    "\n",
    "# Place the modified ROI back into the original bee image\n",
    "bee_img[y_pos:y_pos + flower_height, x_pos:x_pos + flower_width] = result\n",
    "\n",
    "show_img(\"result\",bee_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea1c78f",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a471d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel3 = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "kernel5 = np.full((5,5), -1)\n",
    "kernel5[3,3] = 25\n",
    "\n",
    "img = cv.imread(\"images/native-bee.png\")\n",
    "output3 = cv.filter2D(img, -1, kernel3)\n",
    "output5 = cv.filter2D(img, -1, kernel5)\n",
    "\n",
    "cv.imshow(\"orginal\", img)\n",
    "cv.imshow(\"3x3 kernel\", output3)\n",
    "show_img(\"5x5 kernel\", output5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856134e3",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d538ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/noise_lena.jpg\")\n",
    "\n",
    "#average filter (cv.blur)\n",
    "avg = cv.blur(img, (5, 5))\n",
    "\n",
    "#Gaussian kernel => almost same as avg filter, blur effect more satisfactory\n",
    "gaussian = cv.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "#Median filter => good for removing salt and pepper noise\n",
    "median = cv.medianBlur(img, 5)\n",
    "\n",
    "cv.imshow(\"original\", img)\n",
    "cv.imshow(\"average\", avg)\n",
    "cv.imshow(\"gaussian\", gaussian)\n",
    "show_img(\"median\", median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9244cc2",
   "metadata": {},
   "source": [
    "Median filter produce the best result, most noise are removed and cleared. The average filter has the second best performance but the image become burred. While gaussian filter maintain the image resolution but left some noise in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d143bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
